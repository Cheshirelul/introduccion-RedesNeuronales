# Introducción a Redes Neuronales

*Este repositorio esta en construcción :D*
See you later !

En este repositorio se abarcaran temas introductorios a las redes neruonales tanto clasicas como convolucionales y sus elementos básicos, al inicio se tratara de no abordar tantas formulas matematicas, para tratar de no confundir a aquellas personas no tan familiarizadas y/o con falta de interes en la parte matematica, sin embargo en las partes que sea absolutamente necesario, se abordaran estos temas. Ademas de que estan incluidos ejercicios practicos con sus resultados, tambien contara con un ejercicio de redes convolicionales basado en el dataset "dogs vs cats".

## Agradecimientos

La construcción de este repositorio fue gracias a la asesoria de la M. en T.A. Sandra de la Fuente.

## Fuentes y/o recursos consultados

### Recursos

- <https://github.com/SandraFB/Taller_Keras>
- <https://github.com/Laboratorio-imagenes-CICATAQro/Taller-DL-2018>

### Fuentes

- Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., & Salakhutdinov, R. (2014). Dropout: a simple way to prevent neural networks from overfitting. The journal of machine learning research, 15(1), 1929-1958.
- Palmer Pol, A; Montaño Moreno, J.J. (s.f.). ¿Qué son las redes neuronales artificiales? Aplicaciones realizadas en el ámbito de las adicciones.
- Decena, E. (2019). Entendiendo las redes neuronales PART 1. [online] Medium. Available at: <https://medium.com/@eddydecena/entendiendo-las-redes-neuronales-part-1-fca3adf78c5b> [Accessed 30 Ene. 2020].
- Uniqtech. (2019). Understand Cross Entropy Loss in Minutes. [online] Medium. Available at: <https://medium.com/data-science-bootcamp/understand-cross-entropy-loss-in-minutes-9fb263caee9a> [Accessed 30 Ene. 2020].
- Zulkifli, H. (2018). Understanding Learning Rates and How It Improves Performance in Deep Learning. [online] Medium. Available at: <https://towardsdatascience.com/understanding-learning-rates-and-how-it-improves-performance-in-deep-learning-d0d4059c1c10> [Accessed 31 Ene. 2020].
- Brownlee, J. (2019). Dropout Regularization in Deep Learning Models With Keras. [online] Machine Learning Mastery. Available at: <https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/> [Accessed 7 Feb. 2020].
- Matich, D. J. (2001). Redes Neuronales: Conceptos básicos y aplicaciones. Universidad Tecnológica Nacional, México.
- Ultera Burgal J. (2018) Deep Learning básico con Keras (Parte 3): VGG [online] enmilocalfunciona. Available at: <https://enmilocalfunciona.io/deep-learning-basico-con-keras-parte-3-vgg/> [Accessed 7 Feb. 2020]
- Mirjalili, V. (2018). What does the "same" padding parameter in convolution mean in TensorFlow?. [online] Quora. Availabe at: <https://www.quora.com/What-does-the-same-padding-parameter-in-convolution-mean-in-TensorFlow> [Accessed 12 Feb. 2020].
- Pai, P. (2017). Data Augmentation Techniques in CNN using Tensorflow. [online] Medium. Available at: <https://medium.com/@prasad.pai/data-augmentation-techniques-in-cnn-using-tensorflow-371ae43d5be9> [Accessed 17 Feb., 2020].
- Keras. (s.f.). Keras: The Python Deep Learning library. [online] Keras. Available at:  <https://keras.io/>
- Khandelwal, R. L1 and L2 Regularization. [online] Medium. Available at: <https://medium.com/datadriveninvestor/l1-l2-regularization-7f1b4fe948f2> [Accessed 19 Feb. 2020].
- Thas John, R. (2019) Regularization in TensorFlow using Keras API. [online] Medium. Available at: <https://medium.com/@robertjohn_15390/regularization-in-tensorflow-using-keras-api-48aba746ae21> [Accessed 19 Feb. 2020].

Puedes encontrar más referencias en libros recomendados. Disponibles en: <https://machinelearningmastery.com/machine-learning-books/> [Consultado el 13 de Feb., 2020].
